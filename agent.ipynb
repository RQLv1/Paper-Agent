{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tools\n",
    "from tools import GetDOIsTool, GetDOIsCleanTool, GetOriginaltextTool, \\\n",
    "    GetExtracttextTool, StreamModeTool, CleanDBTool, FileRagTool, QueryTool,\\\n",
    "    DataextTool, DatacountTool, FeaextTool, ModelSelTool, ShapplotTool\n",
    "\n",
    "tools = [\n",
    "    GetDOIsTool(description=\"Quickly get the doi of the literature.\"),\n",
    "    GetDOIsCleanTool(description=\"Quickly clean the doi of the literature.\"),\n",
    "    GetOriginaltextTool(description=\"Get the original text of the literature.\"),\n",
    "    GetExtracttextTool(description=\"Get the extracted text of the literature.\"),\n",
    "    StreamModeTool(description=\"create the database.\"),\n",
    "    CleanDBTool(description=\"Clean the database.\"),\n",
    "    FileRagTool(description=\"File quiz tool. analysis file\"),\n",
    "    QueryTool(description=\"File quiz tool. Use when you need to quiz based on uploaded files, no need to upload files again for subsequent queries.\"),\n",
    "    DataextTool(description=\"Extract the jsonl to csv.\"),\n",
    "    DatacountTool(description=\"Count the data.\"),\n",
    "    FeaextTool(description=\"Extract the feature.\"),\n",
    "    ModelSelTool(description=\"Select the model.\"),\n",
    "    ShapplotTool(description=\"Plot the shap.\")\n",
    "]\n",
    "\n",
    "# print(f\"construct {len(tools)} tools:\")\n",
    "# for tool in tools:\n",
    "#     print(f\"- {tool.name}: {tool.description}\")\n",
    "#     if tool.args_schema:\n",
    "#         print(f\" params: {tool.args_schema.model_json_schema()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=\"sk-bcc39a2fd1ec4aaf81bb672f446d1b2d\",\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    model= \"qwen-plus\"\n",
    ")\n",
    "with open(\"prompts/calling_prompts_gradio.txt\", \"r\") as f:\n",
    "    prompts = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请帮我查找在2020年到2025年发表的有关二氧化钛纳米复合材料相关文献并返回doi号\n",
    "# 请帮我查找在2019年电解水相关的文献并返回doi号\n",
    "# 请帮我查找2025年发表的有关甲烷催化重整的论文，并返回论文的doi\n",
    "# 请帮我查找在2024年发表的有关mof合成相关文献并返回doi号\n",
    "# 请帮我查找在2021年到2022年发表的有关高效锂电池相关文献并返回doi号\n",
    "\n",
    "#请帮我查找在2000年到2025年发表的有关ZrO2纳米粒子液相合成相关文献并返回doi号，改变“液相合成”关键词进行5次查询\n",
    "#请帮我查找在2000年到2025年发表的有关CeO2纳米粒子液相合成相关文献并返回doi号，改变“液相合成”关键词进行5次查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please extract the text from original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, prompt=prompts, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"please enter your problem (type 'exit' to end the conversation): \")\n",
    "    if user_input.strip().lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    for chunk in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content = user_input)]}, config\n",
    "    ):\n",
    "        # if \"agent\" in chunk.keys():\n",
    "            \n",
    "        #     if chunk['agent']['messages'][0].content:\n",
    "        #        \n",
    "        #  print(f\"Agent: {chunk['agent']['messages'][0].content}\")\n",
    "        #         print(\"----\")\n",
    "        print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_analysis import FeatureExtractor\n",
    "fea = FeatureExtractor()\n",
    "fea.exe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_sel import ModelSelector\n",
    "modelsel = ModelSelector()\n",
    "modelsel.exe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap, joblib, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res_dir=r\"outputs/saved_models\"\n",
    "input_dir=r\"outputs\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(model_res_dir, \"model_res.csv\"))\n",
    "model_name = df[df['best_r2'] == max(df['best_r2'])]['model'].values[0]\n",
    "X = pd.read_csv(os.path.join(input_dir, \"X.csv\"), index_col= 0)\n",
    "model = joblib.load(f\"{model_res_dir}/{model_name}_best_model.joblib\")\n",
    "explainer = shap.KernelExplainer(model.predict, shap.sample(X, 5))\n",
    "shap_values = explainer.shap_values(X)\n",
    "excluded_features = [col for col in X.columns if 'name' in col.lower() or 'unit' in col.lower()]\n",
    "display_features = [col for col in X.columns if col not in excluded_features]\n",
    "display_feature_indices = [X.columns.get_loc(col) for col in display_features]\n",
    "X_display = X[display_features]\n",
    "shap_values_display = shap_values[:, display_feature_indices]\n",
    "shap.summary_plot(shap_values_display, X_display, show=False, max_display=8)\n",
    "\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "current_xlabel = ax.get_xlabel()\n",
    "ax.set_xlabel(current_xlabel, color='black', fontdict={'weight': 'bold', 'size': 12})\n",
    "\n",
    "for label in ax.get_xticklabels():\n",
    "    label.set_fontweight('bold')\n",
    "    label.set_color('black')\n",
    "for label in ax.get_yticklabels(): \n",
    "    label.set_fontweight('bold')\n",
    "    label.set_color('black')\n",
    "if len(fig.axes) > 1 and fig.axes[-1] is not ax:\n",
    "    cbar_ax = fig.axes[-1]\n",
    "    if hasattr(cbar_ax, 'yaxis') and cbar_ax.get_ylabel():\n",
    "         cbar_ax.yaxis.label.set_fontweight('bold')\n",
    "         cbar_ax.yaxis.label.set_color('black')\n",
    "    for label in cbar_ax.get_xticklabels() + cbar_ax.get_yticklabels():\n",
    "        label.set_fontweight('bold')\n",
    "        label.set_color('black')\n",
    "\n",
    "save_path = os.path.join(input_dir, \"shap.png\")\n",
    "plt.savefig(save_path, format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
