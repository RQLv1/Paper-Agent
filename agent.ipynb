{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tools\n",
    "from tools import GetDOIsTool, GetDOIsCleanTool, GetOriginaltextTool, \\\n",
    "    GetExtracttextTool, StreamModeTool, CleanDBTool, FileRagTool, QueryTool,\\\n",
    "    DataextTool, DatacountTool, FeaextTool, ModelSelTool, ShapplotTool\n",
    "\n",
    "tools = [\n",
    "    GetDOIsTool(description=\"Quickly get the doi of the literature.\"),\n",
    "    GetDOIsCleanTool(description=\"Quickly clean the doi of the literature.\"),\n",
    "    GetOriginaltextTool(description=\"Get the original text of the literature.\"),\n",
    "    GetExtracttextTool(description=\"Get the extracted text of the literature.\"),\n",
    "    StreamModeTool(description=\"create the database.\"),\n",
    "    CleanDBTool(description=\"Clean the database.\"),\n",
    "    FileRagTool(description=\"File quiz tool. analysis file\"),\n",
    "    QueryTool(description=\"File quiz tool. Use when you need to quiz based on uploaded files, no need to upload files again for subsequent queries.\"),\n",
    "    DataextTool(description=\"Extract the jsonl to csv.\"),\n",
    "    DatacountTool(description=\"Count the data.\"),\n",
    "    FeaextTool(description=\"Extract the feature.\"),\n",
    "    ModelSelTool(description=\"Select the model.\"),\n",
    "    ShapplotTool(description=\"Plot the shap.\")\n",
    "]\n",
    "\n",
    "# print(f\"construct {len(tools)} tools:\")\n",
    "# for tool in tools:\n",
    "#     print(f\"- {tool.name}: {tool.description}\")\n",
    "#     if tool.args_schema:\n",
    "#         print(f\" params: {tool.args_schema.model_json_schema()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    openai_api_key=\"\", # your api key\n",
    "    base_url=\"\", # your api url\n",
    "    model= \"qwen-plus\"\n",
    ")\n",
    "with open(\"prompts/calling_prompts_gradio.txt\", \"r\") as f:\n",
    "    prompts = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, prompt=prompts, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"please enter your problem (type 'exit' to end the conversation): \")\n",
    "    if user_input.strip().lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    for chunk in agent_executor.stream(\n",
    "        {\"messages\": [HumanMessage(content = user_input)]}, config\n",
    "    ):\n",
    "        if \"agent\" in chunk.keys():\n",
    "            \n",
    "            if chunk['agent']['messages'][0].content:\n",
    "               \n",
    "                print(f\"Agent: {chunk['agent']['messages'][0].content}\")\n",
    "                print(\"----\")\n",
    "        # print(chunk)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
